{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from together import Together\n",
    "import json, csv\n",
    "load_dotenv('/Users/guida/llm_argument_tasks/.env')\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import RequestOptions\n",
    "from google.api_core import retry\n",
    "from google.auth import default, transport\n",
    "from modelsmith import Forge, VertexAIGenerativeModel\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Part\n",
    "from dotenv import load_dotenv\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.environ.get('GEMINI_PROJECT_ID')\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from random import sample\n",
    "import jsonlines as jsonl\n",
    "from openai import OpenAI\n",
    "import typing_extensions as typing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentClassification(typing.TypedDict):\n",
    "    id: str \n",
    "    label: int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {1: 1, 2: 1, 3: 0, 4: 1, 5:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for label-to-argument mappings for each topic\n",
    "topic_label_to_argument = {\n",
    "    \"abortion\": {\n",
    "        \"p-right\": \"Abortion is a womanâ€™s right.\",\n",
    "        \"p-rape\": \"Rape victims need it to be legal.\",\n",
    "        \"p-not_human\": \"A fetus is not a human yet, so it's okay to abort.\",\n",
    "        \"p-mother_danger\": \"Abortion should be allowed when a mother's life is in danger.\",\n",
    "        \"p-baby_ill_treatment\": \"Unwanted babies are ill-treated by parents and/or not always adopted.\",\n",
    "        \"p-birth_ctrl\": \"Birth control fails at times and abortion is one way to deal with it.\",\n",
    "        \"p-not_murder\": \"Abortion is not murder.\",\n",
    "        \"p-sick_mom\": \"Mother is not healthy/financially solvent.\",\n",
    "        \"p-other\": \"Others\",\n",
    "        \"c-adopt\": \"Put baby up for adoption.\",\n",
    "        \"c-kill\": \"Abortion kills a life.\",\n",
    "        \"c-baby_right\": \"An unborn baby is a human and has the right to live.\",\n",
    "        \"c-sex\": \"Be willing to have the baby if you have sex.\",\n",
    "        \"c-bad_4_mom\": \"Abortion is harmful for women.\",\n",
    "        \"c-other\": \"Others\"\n",
    "    },\n",
    "    \"gayRights\": {\n",
    "        \"p-normal\": \"Gay marriage is like any other marriage.\",\n",
    "        \"p-right_denied\": \"Gay people should have the same rights as straight people.\",\n",
    "        \"p-no_threat_for_child\": \"Gay parents can adopt and ensure a happy life for a baby.\",\n",
    "        \"p-born\": \"People are born gay.\",\n",
    "        \"p-religion\": \"Religion should not be used against gay rights.\",\n",
    "        \"p-Other\": \"Others\",\n",
    "        \"c-religion\": \"Religion does not permit gay marriages.\",\n",
    "        \"c-abnormal\": \"Gay marriages are not normal/against nature.\",\n",
    "        \"c-threat_to_child\": \"Gay parents cannot raise kids properly.\",\n",
    "        \"c-gay_problems\": \"Gay people have problems and create social issues.\",\n",
    "        \"c-Other\": \"Others\"\n",
    "    },\n",
    "    \"obama\": {\n",
    "        \"p-economy\": \"Fixed the economy.\",\n",
    "        \"p-War\": \"Ending the wars.\",\n",
    "        \"p-republicans\": \"Better than the republican candidates.\",\n",
    "        \"p-decision_policies\": \"Makes good decisions/policies.\",\n",
    "        \"p-quality\": \"Has qualities of a good leader.\",\n",
    "        \"p-health\": \"Ensured better healthcare.\",\n",
    "        \"p-foreign_policies\": \"Executed effective foreign policies.\",\n",
    "        \"p-job\": \"Created more jobs.\",\n",
    "        \"p-Other\": \"Others\",\n",
    "        \"c-economy\": \"Destroyed our economy.\",\n",
    "        \"c-War\": \"Wars are still on.\",\n",
    "        \"c-job\": \"Unemployment rate is high.\",\n",
    "        \"c-health\": \"Healthcare bill is a failure.\",\n",
    "        \"c-decision_policies\": \"Poor decision-maker.\",\n",
    "        \"c-republicans\": \"We have better republicans than Obama.\",\n",
    "        \"c-quality\": \"Not eligible as a leader.\",\n",
    "        \"c-foreign_policies\": \"Ineffective foreign policies.\",\n",
    "        \"c-Other\": \"Others\"\n",
    "    },\n",
    "    \"marijuana\": {\n",
    "        \"p-not_addictive\": \"Not addictive.\",\n",
    "        \"p-medicine\": \"Used as a medicine for its positive effects.\",\n",
    "        \"p-legal\": \"Legalized marijuana can be controlled and regulated by the government.\",\n",
    "        \"p-right\": \"Prohibition violates human rights.\",\n",
    "        \"p-no_damage\": \"Does not cause any damage to our bodies.\",\n",
    "        \"p-Other\": \"Others\",\n",
    "        \"c-health\": \"Damages our bodies.\",\n",
    "        \"c-mind\": \"Responsible for brain damage.\",\n",
    "        \"c-illegal\": \"If legalized, people will use marijuana and other drugs more.\",\n",
    "        \"c-crime\": \"Causes crime.\",\n",
    "        \"c-addiction\": \"Highly addictive.\",\n",
    "        \"c-Other\": \"Others\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples_comarg(samples_file, topic, n):\n",
    "    df = pd.read_csv(samples_file)\n",
    "    ids = df['id'].to_list()\n",
    "    sampled = sample(ids, n)\n",
    "    print(sampled)\n",
    "    df = df[df['id'].isin(sampled)]\n",
    "    comment = df.iloc[0]['comment_text']\n",
    "    output = f\"Comment: {comment}\\n The following arguments are present (1) or not present (0) in this comment:\\n\"\n",
    "    for i, row in df.iterrows():\n",
    "        argument = row['argument_text']\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        label = label_mapping[row['label']]\n",
    "        output = f\"{output} Label: {label}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fewshot_samples(samples_file, topic):\n",
    "    df = pd.read_csv(samples_file)\n",
    "    output = ''\n",
    "    for i, row in df.iterrows():\n",
    "        comment = row['text']\n",
    "        output = f\"{output}\\n Comment: {comment}\\n The following arguments are present (1) or not present (0) in this comment:\\n\"\n",
    "        argument_type = row['label']\n",
    "        argument = topic_label_to_argument[topic][argument_type]\n",
    "        output = f\"{output} Argument {i}: {argument}\\n\"\n",
    "        label = row['present']\n",
    "        output = f\"{output} Label: {label}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(id: str, comment_text: str, topic: str, argument: str, samples: str) -> dict:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        \n",
    "        safety_settings = {\n",
    "            \"HARM_CATEGORY_HARASSMENT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_HATE_SPEECH\": \"block_none\",\n",
    "            \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"block_none\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "                Analyze whether the following comment about {topic} contains a specific argument.\n",
    "\n",
    "                Comment to analyze: {comment_text}\n",
    "                Argument to check for: {argument}\n",
    "\n",
    "                Instructions:\n",
    "                1. Determine if the comment explicitly or implicitly uses the given argument\n",
    "                2. Assign a binary label:\n",
    "                - 1 if the argument is present\n",
    "                - 0 if the argument is not present\n",
    "\n",
    "                Requirements:\n",
    "                - Only use 1 or 0 as labels\n",
    "                - Provide output in valid JSON format\n",
    "                - Do not repeat or include the input text in the response\n",
    "                - Focus solely on the presence/absence of the specific argument\n",
    "\n",
    "                Return your analysis in this exact JSON format:\n",
    "                {{\n",
    "                    \"id\": \"{id}\",\n",
    "                    \"label\": label_value\n",
    "                }}\n",
    "\n",
    "                where label_value must be either 1 or 0 (without quotes)\n",
    "                \n",
    "                Some examples:\n",
    "\n",
    "                {samples}\n",
    "\n",
    "                Analyze the following comment in relation to the given argument:\n",
    "\n",
    "                {comment_text}\n",
    "            \"\"\"\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=ArgumentClassification,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "            ),\n",
    "            safety_settings=safety_settings\n",
    "    )\n",
    "        \n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_comments(df: pd.DataFrame, topic: str, file_name: str, samples: str, n: int):\n",
    "    \n",
    "    with jsonl.open(f'/Users/guida/llm_argument_tasks/evaluation-lea/comarg-task1/gemini/Split1/1-s/comarg_{file_name}_identification_gemini_{n}shot_split_1.jsonl', mode='w') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), desc=\"Processing comments\", unit=\"comment\", total=len(df)):\n",
    "            comment_id = row['id'] \n",
    "            comment_text = row['comment_text']  \n",
    "            argument = row['argument_text']  \n",
    "            try:\n",
    "                classification = classify_text(\n",
    "                    id=comment_id, \n",
    "                    comment_text=comment_text,  \n",
    "                    topic=topic,\n",
    "                    argument=argument,\n",
    "                    samples=samples\n",
    "                )\n",
    "\n",
    "                classification = json.loads(classification)\n",
    "                output_entry = {\"id\": comment_id, \"label\": classification[\"label\"]}\n",
    "                #print(output_entry)\n",
    "                writer.write(output_entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 0}\n",
    "                writer.write(error_entry)\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 0}\n",
    "                writer.write(error_entry)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['108arg2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/1379 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1379/1379 [15:43<00:00,  1.46comment/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_all_arguments_main.csv')\n",
    "topic = 'gay marriage'\n",
    "file_name = 'gm'\n",
    "n = 1\n",
    "samples = prep_fewshot_samples_comarg('/Users/guida/llm_argument_tasks/clean_data/GM_structured_one_shot.csv', topic, n)\n",
    "process_dataframe_comments(gm, topic, file_name, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['198arg5', '5arg5', '108arg2', '161arg4', '175arg4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1379/1379 [13:48<00:00,  1.66comment/s]\n"
     ]
    }
   ],
   "source": [
    "gm = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/GM_all_arguments_main.csv')\n",
    "topic = 'gay marriage'\n",
    "file_name = 'gm'\n",
    "n = 5\n",
    "samples = prep_fewshot_samples_comarg('/Users/guida/llm_argument_tasks/clean_data/GM_structured_shots.csv', topic, n)\n",
    "\n",
    "process_dataframe_comments(gm, topic, file_name, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UGIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721738arg1', '414721922arg3', '414721831arg6', '414721727arg3', '414721757arg6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/2094 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2094/2094 [22:06<00:00,  1.58comment/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_all_arguments_main.csv')\n",
    "topic = 'whether \"Under God\" should appear in the US Pledge of Allegiance'\n",
    "file_name = 'ugip'\n",
    "n = 5\n",
    "samples = prep_fewshot_samples_comarg('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_shots.csv', topic, n)\n",
    "\n",
    "process_dataframe_comments(ugip, topic, file_name, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['414721757arg6']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/2094 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2094/2094 [22:27<00:00,  1.55comment/s]\n"
     ]
    }
   ],
   "source": [
    "ugip = pd.read_csv('/Users/guida/llm_argument_tasks/clean_data/UGIP_all_arguments_main.csv')\n",
    "topic = 'whether \"Under God\" should appear in the US Pledge of Allegiance'\n",
    "file_name = 'ugip'\n",
    "n = 1\n",
    "samples = prep_fewshot_samples_comarg('/Users/guida/llm_argument_tasks/clean_data/UGIP_structured_one_shot.csv', topic, n)\n",
    "\n",
    "process_dataframe_comments(ugip, topic, file_name, samples, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(id: str, comment_text: str, topic: str, argument: str, samples: str) -> dict:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        \n",
    "        safety_settings = {\n",
    "            \"HARM_CATEGORY_HARASSMENT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_HATE_SPEECH\": \"block_none\",\n",
    "            \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"block_none\",\n",
    "            \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"block_none\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "                Analyze whether the following comment about {topic} contains a specific argument.\n",
    "\n",
    "                Comment to analyze: {comment_text}\n",
    "                Argument to check for: {argument}\n",
    "\n",
    "                Instructions:\n",
    "                1. Determine if the comment explicitly or implicitly uses the given argument\n",
    "                2. Assign a binary label:\n",
    "                - 1 if the argument is present\n",
    "                - 0 if the argument is not present\n",
    "\n",
    "                Requirements:\n",
    "                - Only use 1 or 0 as labels\n",
    "                - Provide output in valid JSON format\n",
    "                - Do not repeat or include the input text in the response\n",
    "                - Focus solely on the presence/absence of the specific argument\n",
    "\n",
    "                Return your analysis in this exact JSON format:\n",
    "                {{\n",
    "                    \"id\": \"{id}\",\n",
    "                    \"label\": label_value\n",
    "                }}\n",
    "\n",
    "                where label_value must be either 1 or 0 (without quotes)\n",
    "                \n",
    "                Some examples:\n",
    "\n",
    "                {samples}\n",
    "\n",
    "                Analyze the following comment in relation to the given argument:\n",
    "\n",
    "                {comment_text}\n",
    "            \"\"\"\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=ArgumentClassification,\n",
    "                temperature=0,\n",
    "                top_p=1,\n",
    "            ),\n",
    "            safety_settings=safety_settings\n",
    "    )\n",
    "        \n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_comments(df: pd.DataFrame, topic: str, samples: str, n: int):\n",
    "    label_to_argument = topic_label_to_argument.get(topic, {}) \n",
    "    with jsonl.open(f'/Users/guida/llm_argument_tasks/run_all_k_shots/task1/shot_1/yru_{topic}_identification_gemini_{n}shot.jsonl', mode='w') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), desc=\"Processing comments\", unit=\"comment\", total=len(df)):\n",
    "            comment_id = row['uid'] \n",
    "            comment_text = row['text']  \n",
    "            comment_label = row['label']  \n",
    "\n",
    "            argument_text = label_to_argument.get(comment_label)\n",
    "            try:\n",
    "                classification = classify_text(\n",
    "                    id=comment_id, \n",
    "                    comment_text=comment_text,  \n",
    "                    topic=topic,\n",
    "                    argument=argument_text,\n",
    "                    samples=samples\n",
    "                )\n",
    "                classification = json.loads(classification)\n",
    "                output_entry = {\"id\": comment_id, \"label\": classification[\"label\"]}\n",
    "                #print(output_entry)\n",
    "                writer.write(output_entry)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSONDecodeError for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 0}\n",
    "                writer.write(error_entry)\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred for comment: {comment_text[:50]}... - Error: {e}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 0}\n",
    "                writer.write(error_entry)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/6685 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6685/6685 [1:10:03<00:00,  1.59comment/s]\n",
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6685/6685 [1:15:29<00:00,  1.48comment/s]\n"
     ]
    }
   ],
   "source": [
    "topic = 'abortion'\n",
    "\n",
    "for n in [1, 5]:\n",
    "\n",
    "    df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_main.csv')\n",
    "    \n",
    "    samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_{n}shot.csv', topic)\n",
    "    process_dataframe_comments(df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marijuana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 2/5011 [00:01<56:26,  1.48comment/s]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5011/5011 [56:25<00:00,  1.48comment/s]  \n",
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5011/5011 [1:01:11<00:00,  1.36comment/s]\n"
     ]
    }
   ],
   "source": [
    "topic = 'marijuana'\n",
    "\n",
    "for n in [1, 5]:\n",
    "\n",
    "    df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_main.csv')\n",
    "    \n",
    "    samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_{n}shot.csv', topic)\n",
    "\n",
    "    process_dataframe_comments(df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/7915 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7915/7915 [1:27:39<00:00,  1.50comment/s]\n",
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7915/7915 [1:30:56<00:00,  1.45comment/s]  \n"
     ]
    }
   ],
   "source": [
    "topic = 'obama'\n",
    "\n",
    "for n in [1, 5]:\n",
    "\n",
    "    df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_main.csv')\n",
    "    \n",
    "    samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_{n}shot.csv', topic)\n",
    "\n",
    "    process_dataframe_comments(df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gay Rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:   0%|          | 0/5847 [00:00<?, ?comment/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5847/5847 [1:03:48<00:00,  1.53comment/s]\n",
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5847/5847 [1:05:02<00:00,  1.50comment/s]\n"
     ]
    }
   ],
   "source": [
    "topic = 'gayRights'\n",
    "\n",
    "for n in [1, 5]:\n",
    "\n",
    "    df = pd.read_csv(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_main.csv')\n",
    "    \n",
    "    samples = prep_fewshot_samples(f'/Users/guida/llm_argument_tasks/clean_data/yru_{topic}_with_negatives_{n}shot.csv', topic)\n",
    "\n",
    "    process_dataframe_comments(df, topic, samples, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run remaining splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/guida/llm_argument_tasks/results_T1_gemini_splits/Split2/yru_gayRights_identification_gemini_1shot_split_2.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5847/5847 [1:05:28<00:00,  1.49comment/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\\nsplits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\\nbase_output_path = '/Users/guida/llm_argument_tasks/results_T1_gemini_splits'\\n\\n# Process ComArg datasets\\nrun_splits_for_dataset('comarg', 'gm', base_data_path, splits_path, base_output_path, 4, [1, 5])\\nrun_splits_for_dataset('comarg', 'ugip', base_data_path, splits_path, base_output_path, 4, [1, 5])\\n\\n# Process YRU datasets\\nfor topic in ['abortion', 'marijuana', 'obama', 'gayRights']:\\n    run_splits_for_dataset('yru', topic, base_data_path, splits_path, base_output_path, 4, [1, 5])\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_existing_output(output_file):\n",
    "    \"\"\"Check if output file exists and is complete (not empty/corrupted)\"\"\"\n",
    "    if not os.path.exists(output_file):\n",
    "        return False\n",
    "    try:\n",
    "        # Try to read the file to ensure it's not corrupted\n",
    "        with jsonl.open(output_file) as reader:\n",
    "            entries = list(reader)\n",
    "        return len(entries) > 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def create_split_directories(base_output_path, n_splits):\n",
    "    \"\"\"Create directories for each split if they don't exist\"\"\"\n",
    "    for split in range(2, n_splits + 1):\n",
    "        split_dir = os.path.join(base_output_path, f'Split{split}')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "    return base_output_path\n",
    "\n",
    "def run_splits_for_dataset(dataset_type, topic, base_data_path, splits_path, base_output_path, n_splits, n_shots):\n",
    "    \"\"\"\n",
    "    Run the analysis for a dataset across multiple splits, skipping already processed files.\n",
    "    \"\"\"\n",
    "    # Create split directories\n",
    "    create_split_directories(base_output_path, n_splits)\n",
    "    \n",
    "    for n_shot in n_shots:\n",
    "        for split in range(2, n_splits + 1):\n",
    "            # Define output directory for this split\n",
    "            output_dir = os.path.join(base_output_path, f'Split{split}')\n",
    "            \n",
    "            # Construct file names based on dataset type\n",
    "            if dataset_type == 'comarg':\n",
    "                if topic.lower() == 'gm':\n",
    "                    base_file = 'GM_all_arguments_main.csv'\n",
    "                    split_file = f'GM_all_arguments_main_{n_shot}shot_split_{split}.csv'\n",
    "                    file_name = 'gm'\n",
    "                else:  # UGIP\n",
    "                    base_file = 'UGIP_all_arguments_main.csv'\n",
    "                    split_file = f'UGIP_all_arguments_main_{n_shot}shot_split_{split}.csv'\n",
    "                    file_name = 'ugip'\n",
    "                \n",
    "                output_file = os.path.join(output_dir, f'comarg_{file_name}_identification_gemini_{n_shot}shot_split_{split}.jsonl')\n",
    "                \n",
    "                # Skip if file already exists and is complete\n",
    "                if check_existing_output(output_file):\n",
    "                    print(f\"Skipping existing file: {output_file}\")\n",
    "                    continue\n",
    "                \n",
    "                # Read the data\n",
    "                df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "                topic_name = 'gay marriage' if topic.lower() == 'gm' else 'whether \"Under God\" should appear in the US Pledge of Allegiance'\n",
    "                \n",
    "                # Get samples for this split\n",
    "                samples = prep_fewshot_samples_comarg(\n",
    "                    os.path.join(splits_path, split_file),\n",
    "                    topic_name,\n",
    "                    n_shot\n",
    "                )\n",
    "                \n",
    "                process_dataframe_comments(df, topic_name, file_name, samples, n_shot, output_file)\n",
    "                \n",
    "            else:  # YRU datasets\n",
    "                base_file = f'yru_{topic}_with_negatives_main.csv'\n",
    "                split_file = f'yru_{topic}_with_negatives_main_{n_shot}shot_split_{split}.csv'\n",
    "                output_file = os.path.join(output_dir, f'yru_{topic}_identification_gemini_{n_shot}shot_split_{split}.jsonl')\n",
    "                \n",
    "                # Skip if file already exists and is complete\n",
    "                if check_existing_output(output_file):\n",
    "                    print(f\"Skipping existing file: {output_file}\")\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "                print(f\"Processing file: {output_file}\")\n",
    "                \n",
    "                # Read the data\n",
    "                df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "                \n",
    "                # Get samples for this split\n",
    "                samples = prep_fewshot_samples(\n",
    "                    os.path.join(splits_path, split_file),\n",
    "                    topic\n",
    "                )\n",
    "                \n",
    "                process_yru_dataframe_comments(df, topic, samples, n_shot, output_file)\n",
    "\n",
    "def process_dataframe_comments(df, topic, file_name, samples, n_shot, output_file):\n",
    "    \"\"\"Modified version of the original process_dataframe_comments for comarg datasets\"\"\"\n",
    "    with jsonl.open(output_file, mode='w') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), desc=\"Processing comments\", unit=\"comment\", total=len(df)):\n",
    "            comment_id = row['id']\n",
    "            comment_text = row['comment_text']\n",
    "            argument = row['argument_text']\n",
    "            \n",
    "            try:\n",
    "                classification = classify_text(\n",
    "                    id=comment_id,\n",
    "                    comment_text=comment_text,\n",
    "                    topic=topic,\n",
    "                    argument=argument,\n",
    "                    samples=samples\n",
    "                )\n",
    "                classification = json.loads(classification)\n",
    "                output_entry = {\"id\": comment_id, \"label\": classification[\"label\"]}\n",
    "                writer.write(output_entry)\n",
    "            except (json.JSONDecodeError, Exception) as e:\n",
    "                print(f\"Error processing comment {comment_id}: {str(e)}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 0}\n",
    "                writer.write(error_entry)\n",
    "                \n",
    "def process_yru_dataframe_comments(df, topic, samples, n_shot, output_file):\n",
    "    \"\"\"Modified version of the original process_dataframe_comments for YRU datasets\"\"\"\n",
    "    label_to_argument = topic_label_to_argument.get(topic, {})\n",
    "    with jsonl.open(output_file, mode='w') as writer:\n",
    "        for idx, row in tqdm(df.iterrows(), desc=\"Processing comments\", unit=\"comment\", total=len(df)):\n",
    "            comment_id = row['uid']\n",
    "            comment_text = row['text']\n",
    "            comment_label = row['label']\n",
    "            argument_text = label_to_argument.get(comment_label)\n",
    "            \n",
    "            try:\n",
    "                classification = classify_text(\n",
    "                    id=comment_id,\n",
    "                    comment_text=comment_text,\n",
    "                    topic=topic,\n",
    "                    argument=argument_text,\n",
    "                    samples=samples\n",
    "                )\n",
    "                \n",
    "                classification = json.loads(classification)\n",
    "                output_entry = {\"id\": comment_id, \"label\": classification[\"label\"]}\n",
    "                writer.write(output_entry)\n",
    "            except (json.JSONDecodeError, Exception) as e:\n",
    "                print(f\"Error processing comment {comment_id}: {str(e)}\")\n",
    "                error_entry = {\"id\": comment_id, \"label\": 0}\n",
    "                writer.write(error_entry)\n",
    "                \n",
    "def check_existing_output(file_path):\n",
    "    \"\"\"Check if the output file already exists and is complete.\"\"\"\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "def create_split_directories(base_output_path, n_splits):\n",
    "    \"\"\"Create directories for a specific split (e.g., Split5).\"\"\"\n",
    "    split_dir = os.path.join(base_output_path, f'Split{n_splits}')\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    return split_dir\n",
    "\n",
    "def run_specific_split_for_yru(topic, n_shot, base_data_path, splits_path, base_output_path):\n",
    "    \"\"\"Run the process specifically for 'yru_gayRights_identification_gemini_1shot_split_2.jsonl'.\"\"\"\n",
    "    split = 2  # Since we are re-running Split2\n",
    "    output_dir = create_split_directories(base_output_path, split)\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f'yru_{topic}_identification_gemini_{n_shot}shot_split_{split}.jsonl')\n",
    "    \n",
    "    # Check if the file already exists and is complete\n",
    "    if check_existing_output(output_file):\n",
    "        print(f\"Skipping existing file: {output_file}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing file: {output_file}\")\n",
    "    # Read the data\n",
    "    base_file = f'yru_{topic}_with_negatives_main.csv'\n",
    "    df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "    \n",
    "    # Get samples for this split\n",
    "    split_file = f'yru_{topic}_with_negatives_main_{n_shot}shot_split_{split}.csv'\n",
    "    samples = prep_fewshot_samples(\n",
    "        os.path.join(splits_path, split_file),\n",
    "        topic\n",
    "    )\n",
    "    \n",
    "    # Process the dataframe comments and save the results\n",
    "    process_yru_dataframe_comments(df, topic, samples, n_shot, output_file)\n",
    "\n",
    "# Run the specific split for 'gayRights' and '1shot' on Split2\n",
    "base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\n",
    "splits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\n",
    "base_output_path = '/Users/guida/llm_argument_tasks/results_T1_gemini_splits'\n",
    "\n",
    "# Call the function to process this specific split\n",
    "run_specific_split_for_yru('gayRights', 1, base_data_path, splits_path, base_output_path)\n",
    "                \n",
    "\"\"\"base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\n",
    "splits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\n",
    "base_output_path = '/Users/guida/llm_argument_tasks/results_T1_gemini_splits'\n",
    "\n",
    "# Process ComArg datasets\n",
    "run_splits_for_dataset('comarg', 'gm', base_data_path, splits_path, base_output_path, 4, [1, 5])\n",
    "run_splits_for_dataset('comarg', 'ugip', base_data_path, splits_path, base_output_path, 4, [1, 5])\n",
    "\n",
    "# Process YRU datasets\n",
    "for topic in ['abortion', 'marijuana', 'obama', 'gayRights']:\n",
    "    run_splits_for_dataset('yru', topic, base_data_path, splits_path, base_output_path, 4, [1, 5])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/guida/llm_argument_tasks/evaluation-lea/comarg-task1/gemini/Split1/5-s/comarg_gm_identification_gemini_5shot_split_1.jsonl\n",
      "['198arg5', '175arg4', '161arg4', '5arg5', '108arg2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1379/1379 [15:02<00:00,  1.53comment/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/guida/llm_argument_tasks/evaluation-lea/comarg-task1/gemini/Split1/5-s/comarg_ugip_identification_gemini_5shot_split_1.jsonl\n",
      "['414721738arg1', '414721831arg6', '414721757arg6', '414721922arg3', '414721727arg3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 771/2094 [08:56<43:58,  1.99s/comment]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing comment 414721771arg3: 500 Internal error encountered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 772/2094 [08:56<35:42,  1.62s/comment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing comment 414721771arg4: 500 Internal error encountered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2094/2094 [23:41<00:00,  1.47comment/s]\n"
     ]
    }
   ],
   "source": [
    "def run_specific_comarg_splits(dataset_type, topics, base_data_path, splits_path, output_path, n_shot):\n",
    "    \"\"\"\n",
    "    Run specific splits for ComArg datasets.\n",
    "    \n",
    "    Args:\n",
    "        dataset_type (str): Type of dataset ('comarg')\n",
    "        topics (list): List of topics to process ('gm' or 'ugip')\n",
    "        base_data_path (str): Path to base data directory\n",
    "        splits_path (str): Path to splits directory\n",
    "        output_path (str): Path to save output files\n",
    "        n_shot (int): Number of shots to use\n",
    "    \"\"\"\n",
    "    for topic in topics:\n",
    "        # Construct file names based on topic\n",
    "        if topic.lower() == 'gm':\n",
    "            base_file = 'GM_all_arguments_main.csv'\n",
    "            split_file = f'GM_all_arguments_main_{n_shot}shot_split_1.csv'\n",
    "            file_name = 'gm'\n",
    "        else:  # UGIP\n",
    "            base_file = 'UGIP_all_arguments_main.csv'\n",
    "            split_file = f'UGIP_all_arguments_main_{n_shot}shot_split_1.csv'\n",
    "            file_name = 'ugip'\n",
    "        \n",
    "        output_file = os.path.join(output_path, f'comarg_{file_name}_identification_gemini_{n_shot}shot_split_1.jsonl')\n",
    "        \n",
    "        # Skip if file already exists and is complete\n",
    "        if check_existing_output(output_file):\n",
    "            print(f\"Skipping existing file: {output_file}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing file: {output_file}\")\n",
    "        \n",
    "        # Read the data\n",
    "        df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "        topic_name = 'gay marriage' if topic.lower() == 'gm' else 'whether \"Under God\" should appear in the US Pledge of Allegiance'\n",
    "        \n",
    "        # Get samples for this split\n",
    "        samples = prep_fewshot_samples_comarg(\n",
    "            os.path.join(splits_path, split_file),\n",
    "            topic_name,\n",
    "            n_shot\n",
    "        )\n",
    "        \n",
    "        process_dataframe_comments(df, topic_name, file_name, samples, n_shot, output_file)\n",
    "\n",
    "base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\n",
    "splits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\n",
    "output_path = '/Users/guida/llm_argument_tasks/evaluation-lea/comarg-task1/gemini/Split1/5-s'\n",
    "\n",
    "topics_to_run = ['gm', 'ugip']\n",
    "run_specific_comarg_splits('comarg', topics_to_run, base_data_path, splits_path, output_path, n_shot=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/guida/llm_argument_tasks/results_T1_llama_splits/Split2/yru_gayRights_identification_gemini_1shot_split_2.jsonl\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_yru_dataframe_comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m base_output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/guida/llm_argument_tasks/results_T1_llama_splits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Call the function to process this specific split\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m \u001b[43mrun_specific_split_for_yru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgayRights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_output_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Run only on Split5\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\"base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03msplits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mbase_output_path = '/Users/guida/llm_argument_tasks/results_T1_llama_splits'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03mfor topic in ['gayRights']:\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    run_splits_for_dataset('yru', topic, base_data_path, splits_path, base_output_path, [1, 5])\"\"\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 107\u001b[0m, in \u001b[0;36mrun_specific_split_for_yru\u001b[0;34m(topic, n_shot, base_data_path, splits_path, base_output_path)\u001b[0m\n\u001b[1;32m    101\u001b[0m samples \u001b[38;5;241m=\u001b[39m prep_fewshot_samples(\n\u001b[1;32m    102\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(splits_path, split_file),\n\u001b[1;32m    103\u001b[0m     topic\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Process the dataframe comments and save the results\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[43mprocess_yru_dataframe_comments\u001b[49m(df, topic, samples, n_shot, output_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_yru_dataframe_comments' is not defined"
     ]
    }
   ],
   "source": [
    "def create_split_directories(base_output_path, n_splits):\n",
    "    \"\"\"Create directories for a specific split (Split5)\"\"\"\n",
    "    split_dir = os.path.join(base_output_path, 'Split5')\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    return base_output_path\n",
    "\n",
    "def run_splits_for_dataset(dataset_type, topic, base_data_path, splits_path, base_output_path, n_shots):\n",
    "    \"\"\"\n",
    "    Run the analysis for a dataset on Split5, skipping already processed files.\n",
    "    \"\"\"\n",
    "    # Create the directory for Split5\n",
    "    create_split_directories(base_output_path, 5)\n",
    "    \n",
    "    for n_shot in n_shots:\n",
    "        # Define output directory for Split5\n",
    "        output_dir = os.path.join(base_output_path, 'Split5')\n",
    "        \n",
    "        # Process Split5 only\n",
    "        split = 5\n",
    "        if dataset_type == 'comarg':\n",
    "            if topic.lower() == 'gm':\n",
    "                base_file = 'GM_all_arguments.csv'\n",
    "                split_file = f'GM_all_arguments_main_{n_shot}shot_split_{split}.csv'\n",
    "                file_name = 'gm'\n",
    "            else:  # UGIP\n",
    "                base_file = 'UGIP_all_arguments_main.csv'\n",
    "                split_file = f'UGIP_all_arguments_main_{n_shot}shot_split_{split}.csv'\n",
    "                file_name = 'ugip'\n",
    "            \n",
    "            output_file = os.path.join(output_dir, f'comarg_{file_name}_identification_gemini_{n_shot}shot_split_{split}.jsonl')\n",
    "            \n",
    "            # Skip if file already exists and is complete\n",
    "            if check_existing_output(output_file):\n",
    "                print(f\"Skipping existing file: {output_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Read the data\n",
    "            df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "            topic_name = 'gay marriage' if topic.lower() == 'gm' else 'whether \"Under God\" should appear in the US Pledge of Allegiance'\n",
    "            \n",
    "            # Get samples for this split\n",
    "            samples = prep_fewshot_samples_comarg(\n",
    "                os.path.join(splits_path, split_file),\n",
    "                topic_name,\n",
    "                n_shot\n",
    "            )\n",
    "            \n",
    "            process_dataframe_comments(df, topic_name, file_name, samples, n_shot, output_file)\n",
    "            \n",
    "        else:  # YRU datasets\n",
    "            base_file = f'yru_{topic}_with_negatives_main.csv'\n",
    "            split_file = f'yru_{topic}_with_negatives_main_{n_shot}shot_split_{split}.csv'\n",
    "            output_file = os.path.join(output_dir, f'yru_{topic}_identification_gemini_{n_shot}shot_split_{split}.jsonl')\n",
    "            \n",
    "            # Skip if file already exists and is complete\n",
    "            if check_existing_output(output_file):\n",
    "                print(f\"Skipping existing file: {output_file}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing file: {output_file}\")\n",
    "            # Read the data\n",
    "            df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "            \n",
    "            # Get samples for this split\n",
    "            samples = prep_fewshot_samples(\n",
    "                os.path.join(splits_path, split_file),\n",
    "                topic\n",
    "            )\n",
    "            \n",
    "            process_yru_dataframe_comments(df, topic, samples, n_shot, output_file)\n",
    "\n",
    "def check_existing_output(file_path):\n",
    "    \"\"\"Check if the output file already exists and is complete.\"\"\"\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "def create_split_directories(base_output_path, n_splits):\n",
    "    \"\"\"Create directories for a specific split (e.g., Split5).\"\"\"\n",
    "    split_dir = os.path.join(base_output_path, f'Split{n_splits}')\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    return split_dir\n",
    "\n",
    "def run_specific_split_for_yru(topic, n_shot, base_data_path, splits_path, base_output_path):\n",
    "    \"\"\"Run the process specifically for 'yru_gayRights_identification_gemini_1shot_split_2.jsonl'.\"\"\"\n",
    "    split = 2  # Since we are re-running Split2\n",
    "    output_dir = create_split_directories(base_output_path, split)\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f'yru_{topic}_identification_gemini_{n_shot}shot_split_{split}.jsonl')\n",
    "    \n",
    "    # Check if the file already exists and is complete\n",
    "    if check_existing_output(output_file):\n",
    "        print(f\"Skipping existing file: {output_file}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing file: {output_file}\")\n",
    "    # Read the data\n",
    "    base_file = f'yru_{topic}_with_negatives_main.csv'\n",
    "    df = pd.read_csv(os.path.join(base_data_path, base_file))\n",
    "    \n",
    "    # Get samples for this split\n",
    "    split_file = f'yru_{topic}_with_negatives_main_{n_shot}shot_split_{split}.csv'\n",
    "    samples = prep_fewshot_samples(\n",
    "        os.path.join(splits_path, split_file),\n",
    "        topic\n",
    "    )\n",
    "    \n",
    "    # Process the dataframe comments and save the results\n",
    "    process_yru_dataframe_comments(df, topic, samples, n_shot, output_file)\n",
    "\n",
    "# Run the specific split for 'gayRights' and '1shot' on Split2\n",
    "base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\n",
    "splits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\n",
    "base_output_path = '/Users/guida/llm_argument_tasks/results_T1_llama_splits'\n",
    "\n",
    "# Call the function to process this specific split\n",
    "run_specific_split_for_yru('gayRights', 1, base_data_path, splits_path, base_output_path)\n",
    "\n",
    "# Run only on Split5\n",
    "\"\"\"\"base_data_path = '/Users/guida/llm_argument_tasks/clean_data'\n",
    "splits_path = '/Users/guida/llm_argument_tasks/run_all_k_shots/k-shots'\n",
    "base_output_path = '/Users/guida/llm_argument_tasks/results_T1_llama_splits'\n",
    "\n",
    "# Process ComArg datasets for Split5\n",
    "run_splits_for_dataset('comarg', 'gm', base_data_path, splits_path, base_output_path, [1, 5])\n",
    "run_splits_for_dataset('comarg', 'ugip', base_data_path, splits_path, base_output_path, [1, 5])\n",
    "\n",
    "# Process YRU datasets for Split5\n",
    "for topic in ['gayRights']:\n",
    "    run_splits_for_dataset('yru', topic, base_data_path, splits_path, base_output_path, [1, 5])\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
